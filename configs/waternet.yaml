# 基础设置
exp_name: "waternet_v1" # 实验名称，用于区分不同的训练版本，这里是waternet_v1。
seed: 42 # 随机种子，设置为42可以保证实验可复现，让每次训练的随机初始化和数据洗牌结果一致。
device: "cuda" # 训练设备，cuda 表示使用GPU加速

# 数据设置
data_root: "./data/UIEB" # 数据集的根目录，这里指向./data/UIEB文件夹，程序会从这里加载训练和验证图片。
batch_size: 8 # 批次大小，每次训练迭代时输入8张图片。这个值越大，对显存的要求越高。
num_workers: 4 # 数据加载的线程数，4个线程并行加载数据，可以加速训练。
image_size: 64 # 输入图片的尺寸，所有图片会被统一缩放到64x64像素。

# 训练设置
epochs: 100 # 训练轮数，整个数据集会被完整训练100次。
lr: 0.0002 # 学习率，控制参数更新的步长，0.0002是一个比较小的初始学习率。
betas: [0.5, 0.999] # Adam优化器的动量参数，用于平滑梯度更新。
val_interval: 1  # 验证间隔，每训练1个epoch就进行一次验证，评估模型在验证集上的表现。

# 损失函数权重
lambda_l1: 1.0 # L1损失的权重，用于衡量像素级差异。
lambda_ssim: 0.5 # 结构相似性（SSIM）损失的权重，用于衡量图像结构的相似性。
lambda_perceptual: 0.1 # 感知损失的权重，用于衡量高层语义特征的差异。

# 保存设置
save_dir: "./experiments" #模型和日志的保存目录，训练好的模型和日志文件会存在./experiments文件夹下。
log_interval: 10  # 日志打印间隔，每训练10个batch就打印一次训练状态（如损失值）。